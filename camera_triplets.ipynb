{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10610292-82ae-4868-8945-a504449595d8",
   "metadata": {},
   "source": [
    "# Leveraging Camera Triplets for Efficient and Accurate Structure-from-Motion\n",
    "\n",
    "https://ee.iisc.ac.in/cvlab/research/camtripsfm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa748f4c-e35d-45dc-a1a2-e0d962439e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ade7021-9251-4854-94f0-ba9375feccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypterparams\n",
    "min_inlier_score = 0  # don't add edges (image pairs) to the graph with num_inliers below this number\n",
    "# 0.3 for small/medium scenes 0.6-0.8 for large scenes\n",
    "score_threshold = 0.3 # averaged relative triplet score threshold, below this edges will be deleted\n",
    "min_component_size = 40  # minimum num images in component to check\n",
    "top_k = None  # keep k largest component only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6d8e5-99b6-41aa-b945-594175b2a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image list has distractors from other locations via megaloc retrieval (tympanon matching)\n",
    "image_list = set(Path(\"image_list.txt\").read_text().rstrip().split(\"\\n\"))\n",
    "\n",
    "database_path = Path(\"recon_dir/database.db\")\n",
    "database_path_out = Path(\"recon_dir/database_triplets.db\")\n",
    "\n",
    "# dir for reconstruction\n",
    "out_path = Path(\"recon_dir_triplets\")\n",
    "out_path.mkdir(exist_ok=True, parents=True)\n",
    "image_dir = Path(\"image_dir_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e481e2-5829-4f7e-9ce6-7d669cf26713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_ids_to_pair_id(image_id1, image_id2):\n",
    "    if image_id1 > image_id2:\n",
    "        return 2147483647 * image_id2 + image_id1\n",
    "    else:\n",
    "        return 2147483647 * image_id1 + image_id2\n",
    "\n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % 2147483647\n",
    "    image_id1 = int((pair_id - image_id2) / 2147483647)\n",
    "    return image_id1, image_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334d08c-023b-4c62-ae9c-dc9982d4a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_triangles_nx(graph):\n",
    "    \"\"\"Use NetworkX's optimized triangle enumeration\"\"\"\n",
    "    triangles = set()\n",
    "    # nx.triangles returns {node: count} dict\n",
    "    # We need to enumerate actual triangles\n",
    "    for edge in graph.edges():\n",
    "        common_neighbors = set(graph.neighbors(edge[0])) & set(graph.neighbors(edge[1]))\n",
    "        for cn in common_neighbors:\n",
    "            triangle = tuple(sorted([edge[0], edge[1], cn]))\n",
    "            triangles.add(triangle)\n",
    "    return list(triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159447e-06a4-4579-900f-c55bd086073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_edges(graph, inlier_counts):\n",
    "    \"\"\"\n",
    "    For every triplet (a,b,c) in the graph:\n",
    "    - compute relative edge score per edge in triplet\n",
    "    - accumulate scores to get final per-edge score\n",
    "    \"\"\"\n",
    "    # accumulate score sums & counts\n",
    "    edge_scores_sum = defaultdict(float)\n",
    "    edge_scores_cnt = defaultdict(int)\n",
    "    triangles = enumerate_triangles_nx(G)\n",
    "    \n",
    "    for (a,b,c) in tqdm(triangles, desc=\"Scoring triplets\"):\n",
    "        # check if edges exist\n",
    "        # if not graph.has_edge(a,b) or not graph.has_edge(b,c) or not graph.has_edge(a,c):\n",
    "        #     continue\n",
    "\n",
    "        eab, ebc, eac = image_ids_to_pair_id(a,b), image_ids_to_pair_id(b,c), image_ids_to_pair_id(a,c)\n",
    "        # get inliers\n",
    "        nab = inlier_counts.get(eab, 0)\n",
    "        nbc = inlier_counts.get(ebc, 0)\n",
    "        nac = inlier_counts.get(eac, 0)\n",
    "\n",
    "        # max\n",
    "        m = max(nab, nbc, nac, 1)\n",
    "        # relative scores\n",
    "        for e,n in [(eab,nab), (ebc,nbc), (eac,nac)]:\n",
    "            score = float(n) / float(m)\n",
    "            edge_scores_sum[e] += score\n",
    "            edge_scores_cnt[e] += 1\n",
    "\n",
    "    # final averages\n",
    "    edge_score = {e: edge_scores_sum[e]/edge_scores_cnt[e] for e in inlier_counts.keys() if edge_scores_cnt[e]>0}\n",
    "\n",
    "    return edge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddf859-10cd-49b3-a29a-98d0795bb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_threshold(graph, min_score=0.5):\n",
    "    \"\"\"\n",
    "    Compute adaptive threshold based on graph connectivity.\n",
    "    \n",
    "    τ = m * (1 - dmax/|V|) + dmax/|V|\n",
    "    \n",
    "    where:\n",
    "    - m is the minimum score edges should satisfy\n",
    "    - dmax is the maximum node degree\n",
    "    - |V| is the number of nodes\n",
    "    \"\"\"\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    if num_nodes == 0:\n",
    "        return min_score\n",
    "    \n",
    "    # Maximum degree in the graph\n",
    "    degrees = dict(graph.degree())\n",
    "    dmax = max(degrees.values()) if degrees else 0\n",
    "    \n",
    "    # Adaptive threshold formula from paper\n",
    "    tau = min_score * (1 - dmax / num_nodes) + (dmax / num_nodes)\n",
    "    \n",
    "    print(f\"Adaptive threshold: τ = {tau:.4f} (dmax={dmax}, |V|={num_nodes}, m={min_score})\")\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474022d8-8092-4f40-b93c-d0db4033b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database has to contain 2 view geometries and inlier matches (Ransac, F/E/H matrix)\n",
    "with pycolmap.Database.open(database_path) as db:\n",
    "    inlier_counts = db.read_two_view_geometry_num_inliers()\n",
    "    image_data = db.read_all_images()\n",
    "id_to_name = {image.image_id: image for image in image_data if image.name in image_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d597850-65cb-4b18-a5ce-1cb1a24f8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(id_to_name.keys()) # image_ids\n",
    "for pair_id, num_inliers in zip(*inlier_counts):\n",
    "    image_id1, image_id2 = pair_id_to_image_ids(pair_id)\n",
    "    if num_inliers >= min_inlier_score:\n",
    "        G.add_edge(image_id1, image_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d03893-af35-40c5-a473-73f18ba1956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all connected components\n",
    "components = list(nx.connected_components(G))\n",
    "\n",
    "print(f\"Found {len(components)} connected components\")\n",
    "\n",
    "# Sort by size (largest first)\n",
    "components_sorted = sorted(components, key=len, reverse=True)\n",
    "\n",
    "# Print component sizes\n",
    "for i, comp in enumerate(components_sorted[:10]):  # Show top 10\n",
    "    print(f\"  Component {i+1}: {len(comp)} nodes\")\n",
    "\n",
    "# Filter by size\n",
    "large_components = [comp for comp in components_sorted if len(comp) >= min_component_size]\n",
    "\n",
    "print(f\"Components with >= {min_component_size} nodes: {len(large_components)}\")\n",
    "\n",
    "# Optionally keep only top k\n",
    "if top_k is not None:\n",
    "    large_components = large_components[:top_k]\n",
    "    print(f\"Keeping top {top_k} largest components\")\n",
    "\n",
    "# Create subgraphs\n",
    "component_graphs = [G.subgraph(comp).copy() for comp in large_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4541f-f930-4aac-b5f0-33103ecfd640",
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_dict = {pair_id: num_inliers for pair_id, num_inliers in zip(*inlier_counts)}\n",
    "edge_scores = score_edges(component_graphs[0], inlier_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f019f0-fc3b-43a8-a173-c4631fbc47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy2(database_path, database_path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180f381-1514-437c-94a5-2e1fc7f0701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = adaptive_threshold(component_graphs[0], min_score=score_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c23d0-03a9-4dbc-967c-8e2c400b3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_removed_edges = 0\n",
    "with pycolmap.Database.open(database_path_out) as db:\n",
    "    for pair_id, score in tqdm(edge_scores.items()):\n",
    "        image_id1, image_id2 = pair_id_to_image_ids(pair_id)\n",
    "        if score < tau:\n",
    "            db.delete_inlier_matches(image_id1, image_id2)\n",
    "            num_removed_edges += 1\n",
    "print(f\"{num_removed_edges} edges with scores lower than {tau=} {score_threshold=} removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d5e2f-2605-4801-be6d-e94196789246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pycolmap.incremental_mapping(database_path_out, image_dir,\n",
    "                            out_path, options=dict(#min_num_matches=100, \n",
    "                                                   multiple_models=True,\n",
    "                                                   ignore_watermarks=True,\n",
    "                                                   snapshot_path=out_path/\"snapshots\",\n",
    "                                                   snapshot_frames_freq=100,\n",
    "                                                   ba_use_gpu=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
